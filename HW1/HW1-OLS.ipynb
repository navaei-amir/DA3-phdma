{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "In the first step we load the data set; filter it based on the occupational code and clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the basic libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "#the necessary libraries for LASSO\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# the necessary libraries for OLS with cross validation\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import KFold\n",
    "# the necessary libraries for considering the interaction terms and powers in model 4\n",
    "from itertools import combinations\n",
    "# the necessary libraries for plotting\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Loading the dataset from the current path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>hhid</th>\n",
       "      <th>intmonth</th>\n",
       "      <th>stfips</th>\n",
       "      <th>weight</th>\n",
       "      <th>earnwke</th>\n",
       "      <th>uhours</th>\n",
       "      <th>grade92</th>\n",
       "      <th>race</th>\n",
       "      <th>ethnic</th>\n",
       "      <th>...</th>\n",
       "      <th>ownchild</th>\n",
       "      <th>chldpres</th>\n",
       "      <th>prcitshp</th>\n",
       "      <th>state</th>\n",
       "      <th>ind02</th>\n",
       "      <th>occ2012</th>\n",
       "      <th>class</th>\n",
       "      <th>unionmme</th>\n",
       "      <th>unioncov</th>\n",
       "      <th>lfsr94</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2600310997690</td>\n",
       "      <td>January</td>\n",
       "      <td>AL</td>\n",
       "      <td>3151.6801</td>\n",
       "      <td>1692.00</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Native, Born In US</td>\n",
       "      <td>63</td>\n",
       "      <td>Employment services (5613)</td>\n",
       "      <td>630</td>\n",
       "      <td>Private, For Profit</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed-At Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>75680310997590</td>\n",
       "      <td>January</td>\n",
       "      <td>AL</td>\n",
       "      <td>3457.1138</td>\n",
       "      <td>450.00</td>\n",
       "      <td>40</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Native, Born In US</td>\n",
       "      <td>63</td>\n",
       "      <td>Outpatient care centers (6214)</td>\n",
       "      <td>5400</td>\n",
       "      <td>Private, For Profit</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed-Absent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>75680310997590</td>\n",
       "      <td>January</td>\n",
       "      <td>AL</td>\n",
       "      <td>3936.9110</td>\n",
       "      <td>1090.00</td>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>Native, Born In US</td>\n",
       "      <td>63</td>\n",
       "      <td>Motor vehicles and motor vehicle equipment man...</td>\n",
       "      <td>8140</td>\n",
       "      <td>Private, For Profit</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed-At Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>179140131100930</td>\n",
       "      <td>January</td>\n",
       "      <td>AL</td>\n",
       "      <td>3288.3640</td>\n",
       "      <td>769.23</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Native, Born In US</td>\n",
       "      <td>63</td>\n",
       "      <td>**Publishing, except newspapers and software (...</td>\n",
       "      <td>8255</td>\n",
       "      <td>Private, For Profit</td>\n",
       "      <td>Yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Employed-At Work</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>179140131100930</td>\n",
       "      <td>January</td>\n",
       "      <td>AL</td>\n",
       "      <td>3422.8500</td>\n",
       "      <td>826.92</td>\n",
       "      <td>40</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Native, Born In US</td>\n",
       "      <td>63</td>\n",
       "      <td>Banking and related activities (521, 52211,52219)</td>\n",
       "      <td>5940</td>\n",
       "      <td>Private, For Profit</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Employed-At Work</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             hhid intmonth stfips     weight  earnwke  uhours  \\\n",
       "0           3    2600310997690  January     AL  3151.6801  1692.00      40   \n",
       "1           5   75680310997590  January     AL  3457.1138   450.00      40   \n",
       "2           6   75680310997590  January     AL  3936.9110  1090.00      60   \n",
       "3          10  179140131100930  January     AL  3288.3640   769.23      40   \n",
       "4          11  179140131100930  January     AL  3422.8500   826.92      40   \n",
       "\n",
       "   grade92  race  ethnic  ...  ownchild  chldpres            prcitshp  state  \\\n",
       "0       43     1     NaN  ...         0         0  Native, Born In US     63   \n",
       "1       41     2     NaN  ...         2         6  Native, Born In US     63   \n",
       "2       41     2     NaN  ...         2         6  Native, Born In US     63   \n",
       "3       40     1     NaN  ...         2         4  Native, Born In US     63   \n",
       "4       43     1     NaN  ...         2         4  Native, Born In US     63   \n",
       "\n",
       "                                               ind02 occ2012  \\\n",
       "0                         Employment services (5613)     630   \n",
       "1                     Outpatient care centers (6214)    5400   \n",
       "2  Motor vehicles and motor vehicle equipment man...    8140   \n",
       "3  **Publishing, except newspapers and software (...    8255   \n",
       "4  Banking and related activities (521, 52211,52219)    5940   \n",
       "\n",
       "                 class unionmme  unioncov            lfsr94  \n",
       "0  Private, For Profit       No        No  Employed-At Work  \n",
       "1  Private, For Profit       No        No   Employed-Absent  \n",
       "2  Private, For Profit       No        No  Employed-At Work  \n",
       "3  Private, For Profit      Yes       NaN  Employed-At Work  \n",
       "4  Private, For Profit       No        No  Employed-At Work  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = pd.read_csv('morg-2014-emp.csv', low_memory= False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the data based on the occupational codes\n",
    "We are going to continue with **__Arts, Design, Entertainment, Sports, and Media Occupations__** in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filtering data based on the Occupational code\n",
    "filtered_data = data[(data['occ2012'] >= 2600) & (data['occ2012'] <= 2920)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Checking the data types to make the necessary adjustments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0      int64\n",
       "hhid            int64\n",
       "intmonth       object\n",
       "stfips         object\n",
       "weight        float64\n",
       "earnwke       float64\n",
       "uhours          int64\n",
       "grade92         int64\n",
       "race            int64\n",
       "ethnic        float64\n",
       "age             int64\n",
       "sex             int64\n",
       "marital         int64\n",
       "ownchild        int64\n",
       "chldpres        int64\n",
       "prcitshp       object\n",
       "state          object\n",
       "ind02          object\n",
       "occ2012         int64\n",
       "class          object\n",
       "unionmme       object\n",
       "unioncov       object\n",
       "lfsr94         object\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting the categorical columns from object to categorical type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\2368441643.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data[col] = pd.Categorical(filtered_data[col])\n"
     ]
    }
   ],
   "source": [
    "cat_cols = [\n",
    "    'intmonth','stfips','prcitshp', 'ind02','class', 'unionmme','unioncov',\n",
    "    'lfsr94', 'race', 'ethnic', 'sex', 'marital','occ2012' \n",
    "]\n",
    "for col in cat_cols:\n",
    "    filtered_data[col] = pd.Categorical(filtered_data[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing values, checking and handling\n",
    "First, let's see which variables include missing values and how can we deal with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0       0\n",
       "hhid             0\n",
       "intmonth         0\n",
       "stfips           0\n",
       "weight           0\n",
       "earnwke          0\n",
       "uhours           0\n",
       "grade92          0\n",
       "race             0\n",
       "ethnic        2107\n",
       "age              0\n",
       "sex              0\n",
       "marital          0\n",
       "ownchild         0\n",
       "chldpres         0\n",
       "prcitshp         0\n",
       "state            0\n",
       "ind02            0\n",
       "occ2012          0\n",
       "class            0\n",
       "unionmme         0\n",
       "unioncov       134\n",
       "lfsr94           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_values = filtered_data.isnull().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Only 2 variables have misisng values and for these 2, it is plausible to replace the missing values with the modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3109804962.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['ethnic'].fillna(filtered_data['ethnic'].mode()[0], inplace=True)\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3109804962.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['unioncov'].fillna(filtered_data['unioncov'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# fill missing values with mode\n",
    "filtered_data['ethnic'].fillna(filtered_data['ethnic'].mode()[0], inplace=True)\n",
    "filtered_data['unioncov'].fillna(filtered_data['unioncov'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\649476128.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_data['hourly_wage'] = filtered_data['earnwke'].div(filtered_data['uhours'])\n"
     ]
    }
   ],
   "source": [
    "# Creating a new variable for hourly wage\n",
    "filtered_data['hourly_wage'] = filtered_data['earnwke'].div(filtered_data['uhours'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the categorical variables to dummies\n",
    "* When we convert a categorical variable to a set of dummies, the sufficient number of dummies is the number of categories minus 1. This is the reason that we drop the first category.\n",
    "* Also, after creating the set of dummies we exclude the original variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the categorical variables to dummies\n",
    "filtered_data = pd.get_dummies(filtered_data, columns = cat_cols, drop_first= True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = cat_cols + ['Unnamed: 0','hhid', 'earnwke', 'uhours','state']\n",
    "keep_cols= [i for i in filtered_data.columns if i not in drop_cols]\n",
    "df = filtered_data[keep_cols].copy()\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "      <th>grade92</th>\n",
       "      <th>age</th>\n",
       "      <th>ownchild</th>\n",
       "      <th>chldpres</th>\n",
       "      <th>hourly_wage</th>\n",
       "      <th>intmonth_August</th>\n",
       "      <th>intmonth_December</th>\n",
       "      <th>intmonth_February</th>\n",
       "      <th>intmonth_January</th>\n",
       "      <th>...</th>\n",
       "      <th>occ2012_2800</th>\n",
       "      <th>occ2012_2810</th>\n",
       "      <th>occ2012_2825</th>\n",
       "      <th>occ2012_2830</th>\n",
       "      <th>occ2012_2840</th>\n",
       "      <th>occ2012_2850</th>\n",
       "      <th>occ2012_2860</th>\n",
       "      <th>occ2012_2900</th>\n",
       "      <th>occ2012_2910</th>\n",
       "      <th>occ2012_2920</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3202.3739</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.350000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9206.4248</td>\n",
       "      <td>40</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1533.1598</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>22.200000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1616.3952</td>\n",
       "      <td>40</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1833.6081</td>\n",
       "      <td>37</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>3374.2812</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.230750</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2311</th>\n",
       "      <td>3677.2160</td>\n",
       "      <td>39</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>10.357143</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2312</th>\n",
       "      <td>3814.6828</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.397222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2313</th>\n",
       "      <td>325.7699</td>\n",
       "      <td>41</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>38.450000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2314</th>\n",
       "      <td>304.4811</td>\n",
       "      <td>43</td>\n",
       "      <td>32</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>11.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2315 rows Ã— 300 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         weight  grade92  age  ownchild  chldpres  hourly_wage  \\\n",
       "0     3202.3739       40   23         0         0     8.350000   \n",
       "1     9206.4248       40   23         0         0     7.750000   \n",
       "2     1533.1598       43   35         2         8    22.200000   \n",
       "3     1616.3952       40   27         1         1    17.500000   \n",
       "4     1833.6081       37   17         0         0    13.500000   \n",
       "...         ...      ...  ...       ...       ...          ...   \n",
       "2310  3374.2812       43   32         1         1    19.230750   \n",
       "2311  3677.2160       39   50         1         4    10.357143   \n",
       "2312  3814.6828       43   57         0         0    23.397222   \n",
       "2313   325.7699       41   36         2         8    38.450000   \n",
       "2314   304.4811       43   32         4        11    11.400000   \n",
       "\n",
       "      intmonth_August  intmonth_December  intmonth_February  intmonth_January  \\\n",
       "0                   0                  0                  0                 1   \n",
       "1                   0                  0                  0                 1   \n",
       "2                   0                  0                  0                 1   \n",
       "3                   0                  0                  0                 1   \n",
       "4                   0                  0                  0                 1   \n",
       "...               ...                ...                ...               ...   \n",
       "2310                0                  1                  0                 0   \n",
       "2311                0                  1                  0                 0   \n",
       "2312                0                  1                  0                 0   \n",
       "2313                0                  1                  0                 0   \n",
       "2314                0                  1                  0                 0   \n",
       "\n",
       "      ...  occ2012_2800  occ2012_2810  occ2012_2825  occ2012_2830  \\\n",
       "0     ...             0             0             0             0   \n",
       "1     ...             0             0             0             0   \n",
       "2     ...             0             0             0             0   \n",
       "3     ...             0             0             0             0   \n",
       "4     ...             0             0             0             0   \n",
       "...   ...           ...           ...           ...           ...   \n",
       "2310  ...             0             0             0             0   \n",
       "2311  ...             0             0             0             0   \n",
       "2312  ...             0             0             0             0   \n",
       "2313  ...             0             0             0             0   \n",
       "2314  ...             0             0             0             1   \n",
       "\n",
       "      occ2012_2840  occ2012_2850  occ2012_2860  occ2012_2900  occ2012_2910  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2310             0             0             0             0             0   \n",
       "2311             0             0             0             0             0   \n",
       "2312             0             0             0             0             0   \n",
       "2313             0             0             0             0             0   \n",
       "2314             0             0             0             0             0   \n",
       "\n",
       "      occ2012_2920  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  \n",
       "...            ...  \n",
       "2310             0  \n",
       "2311             0  \n",
       "2312             0  \n",
       "2313             0  \n",
       "2314             0  \n",
       "\n",
       "[2315 rows x 300 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LASSO and Dropping the insignificant variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As we can see, we have almost 300 explanatory variables. \n",
    "* We will use LASSO to get rid of non-important features. \n",
    "* Then we'll use the rest of the features for implementing the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separating the target variable and the independent variables\n",
    "X = df.drop('hourly_wage', axis=1)\n",
    "y = df['hourly_wage']\n",
    "\n",
    "# normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We use the cross validition with 5 folds to choose the best value for the regulization parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.22171199461445, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 65.84160925738979, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 87.90087860677158, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 96.4451674912707, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 99.56076029333053, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 100.67204487486742, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.06310850247974, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.19813300156966, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.24280807073228, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25593777105678, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25834611372557, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25733058445621, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25541105133016, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25343645719113, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25169631908648, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.25016070064157, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.2488802872831, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.24782968265936, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 101.2469557421282, tolerance: 40.96758572217973\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 75.91424099699361, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 154.96166584140155, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 185.5818155835732, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 195.76818450784776, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 198.94573039602255, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 199.8522549935151, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 131.23321273282636, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 244.03208509460092, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 286.8081115060486, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 301.12528398563154, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 305.73391231376445, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.1784468316473, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6093968132045, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.72041958983755, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.7334508836502, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.71890499891015, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6986950718565, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6793157613138, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6623876768863, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6480685605202, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6360979694873, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6261253441917, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.61784050485585, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 307.6109686153941, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 115.9776228312403, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 253.79121167690028, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 308.1950876090559, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 326.6405234733829, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 332.65355528052896, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 334.58997391187586, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 335.2105435865815, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 335.40858958731405, tolerance: 44.49863693657909\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 194.7746848918614, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 230.07819483272033, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 323.99594033617177, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 386.73642037587706, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 495.08477972229593, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 164.20051454854547, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 331.31899032677757, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 605.0155746283417, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 363.82140498046647, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 819.4088650651975, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 990.4478949996992, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1045.999609351653, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1063.4078669779992, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1068.7869027476409, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.4249387283926, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9073040240328, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.0357688798686, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.058156929037, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.0506199812517, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.0362824177137, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.0218632609758, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1071.0091355640325, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9982974015002, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9892649365938, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9816633780429, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9754195652495, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9702168205113, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9658764925553, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9622569277126, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1070.9593325208407, tolerance: 36.3850747504182\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 54.31766707630595, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 84.97397163626738, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 95.96523786662146, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 170.18078139686259, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 67.79169909155462, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 78.65392443316523, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 192.52434187784093, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 257.4438686730573, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 361.8185213012621, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 396.4699716521427, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 407.17537188745337, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 410.3843899978674, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.3092451185803, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.54836887610145, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.5865457376349, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.5696407100186, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.5408816364943, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 411.5125422468991, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 310.2615801616921, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 390.39978752390016, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 416.28004137577955, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 424.25779904646333, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 426.68056463694666, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.40936971770134, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.62488722463604, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.685691843275, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.7003678950132, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.7017000578344, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.69951691676397, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.69671287818346, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.6940955898026, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.6917926641181, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "c:\\Users\\PA\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:617: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 427.6898974550422, tolerance: 40.99544329315465\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    }
   ],
   "source": [
    "alphas = np.logspace(-6, 2, 100)\n",
    "lasso_cv = LassoCV(alphas=alphas, cv=5)\n",
    "lasso_cv.fit(X_train, y_train)\n",
    "# Stoing the best lambda value\n",
    "selected_alpha = lasso_cv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this step we use the selected value of **__alpha__** to train tha LASSO model and exclude non-important features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=0.5462277217684348)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Lasso</label><div class=\"sk-toggleable__content\"><pre>Lasso(alpha=0.5462277217684348)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Lasso(alpha=0.5462277217684348)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model = Lasso(alpha=selected_alpha)\n",
    "best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting the significant coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['grade92', 'age', 'chldpres', 'stfips_CA', 'stfips_CT', 'stfips_DC',\n",
      "       'stfips_KS', 'stfips_MS', 'stfips_NC', 'stfips_NV', 'stfips_NY',\n",
      "       'stfips_OH', 'stfips_RI', 'stfips_TN', 'stfips_TX', 'stfips_WA',\n",
      "       'stfips_WI', 'prcitshp_Foreign Born, US Cit By Naturalization',\n",
      "       'prcitshp_Native, Born In US',\n",
      "       'ind02_** Apparel, fabrics, and notions, merchant wholesalers (*4243)',\n",
      "       'ind02_5275', 'ind02_Book stores and news dealers (45121)',\n",
      "       'ind02_Building material and supplies dealers (4441 exc. 44413)',\n",
      "       'ind02_Computer systems design and related services (5415)',\n",
      "       'ind02_Electronic component and product manufacturing, n.e.c. (3344, 3346)',\n",
      "       'ind02_Furniture and home furnishings stores (442)',\n",
      "       'ind02_Grocery stores (4451)',\n",
      "       'ind02_Independent artists, performing arts, spectator sports, and related industries (711)',\n",
      "       'ind02_Industrial and miscellaneous chemicals (3251, 3259)',\n",
      "       'ind02_Management, scientific, and technical consulting services (5416)',\n",
      "       'ind02_Museums, art galleries, historical sites, and similar institutions (712)',\n",
      "       'ind02_Navigational, measuring, electromedical, and control instruments manufacturing (3345)',\n",
      "       'ind02_Other amusement, gambling, and recreation industries (713 exc. 71395)',\n",
      "       'ind02_Pipeline transportation (486)',\n",
      "       'ind02_Printing and related support activities (3231)',\n",
      "       'ind02_Religious organizations (8131)',\n",
      "       'ind02_Retail bakeries (311811)', 'ind02_Retail florists (4531)',\n",
      "       'ind02_Scenic and sightseeing transportation (487)',\n",
      "       'ind02_Toys, amusement, and sporting goods manufacturing (33992, 33993)',\n",
      "       'class_Government - State', 'unionmme_Yes', 'race_4', 'race_8', 'sex_2',\n",
      "       'marital_4', 'marital_5', 'marital_7', 'occ2012_2630', 'occ2012_2700',\n",
      "       'occ2012_2710', 'occ2012_2720', 'occ2012_2740', 'occ2012_2760',\n",
      "       'occ2012_2800', 'occ2012_2825', 'occ2012_2910'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_features = X.columns[best_model.coef_ != 0]\n",
    "print(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating lists to store the RMSE and BIC values\n",
    "RMSE_full_sample = []\n",
    "RMSE_CV = []\n",
    "BIC_full_sample = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade92', 'age', 'race_4', 'race_8', 'sex_2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_features = ['race', 'sex', 'weight']\n",
    "model_0_features = ['grade92','age']\n",
    "for feat in zero_features:\n",
    "    model_0_features += [i for i in selected_features if feat in i]\n",
    "\n",
    "model_0_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 5)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_model_0 = X_scaled[:, [i for i in range(X_scaled.shape[1]) if X.columns[i] in model_0_features]]\n",
    "X_scaled_model_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.301824144272633\n"
     ]
    }
   ],
   "source": [
    "model0 = LinearRegression()\n",
    "y_pred_cv = cross_val_predict(model0, X_scaled_model_0, y, cv=5)\n",
    "rmse_cv_value = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "RMSE_CV.append(rmse_cv_value)\n",
    "print(rmse_cv_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with full sample is:  25.271251158873717\n",
      "BIC of OLS model with full sample is:  21569.52860778832\n"
     ]
    }
   ],
   "source": [
    "# Building the OLS model using full sample and calculating the RMSE and BIC\n",
    "X_scaled_model_0 = sm.add_constant(X_scaled_model_0)\n",
    "model0_full_sample = sm.OLS(y, X_scaled_model_0).fit()\n",
    "y_pred_full_sample = model0_full_sample.predict(X_scaled_model_0)\n",
    "rmse_full_sample_value = np.sqrt(mean_squared_error(y, y_pred_full_sample))\n",
    "RMSE_full_sample.append(rmse_full_sample_value)\n",
    "BIC_full_sample.append(model0_full_sample.bic)\n",
    "print('RMSE of OLS model with full sample is: ', rmse_full_sample_value)\n",
    "print('BIC of OLS model with full sample is: ', model0_full_sample.bic)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade92',\n",
       " 'age',\n",
       " 'race_4',\n",
       " 'race_8',\n",
       " 'sex_2',\n",
       " 'prcitshp_Foreign Born, US Cit By Naturalization',\n",
       " 'prcitshp_Native, Born In US']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "basic_features = [ 'race', 'ethnic', 'sex','prcitshp', 'unioncov', 'lfsr94', 'intmonth']\n",
    "model_1_features = ['grade92','age']\n",
    "for feat in basic_features:\n",
    "    model_1_features += [i for i in selected_features if feat in i]\n",
    "\n",
    "model_1_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 7)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_model_1 = X_scaled[:, [i for i in range(len(X.columns)) if X.columns[i] in model_1_features]]\n",
    "X_scaled_model_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with cross validation is:  25.305786947956214\n"
     ]
    }
   ],
   "source": [
    "# Building the OLS model using cross validation\n",
    "model1 = LinearRegression()\n",
    "y_pred_cv = cross_val_predict(model1, X_scaled_model_1, y, cv=5)\n",
    "rmse_cv_value = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "RMSE_CV.append(rmse_cv_value)\n",
    "\n",
    "print('RMSE of OLS model with cross validation is: ', rmse_cv_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with full sample is:  25.268128803746453\n",
      "BIC of OLS model with full sample is:  21584.450849014764\n"
     ]
    }
   ],
   "source": [
    "# Building the OLS model using full sample and calculating the RMSE and BIC\n",
    "X_scaled_model_1 = sm.add_constant(X_scaled_model_1)\n",
    "model1_full_sample = sm.OLS(y, X_scaled_model_1).fit()\n",
    "y_pred_full_sample = model1_full_sample.predict(X_scaled_model_1)\n",
    "rmse_full_sample_value = np.sqrt(mean_squared_error(y, y_pred_full_sample))\n",
    "RMSE_full_sample.append(rmse_full_sample_value)\n",
    "BIC_full_sample.append(model1_full_sample.bic)\n",
    "print('RMSE of OLS model with full sample is: ', rmse_full_sample_value)\n",
    "print('BIC of OLS model with full sample is: ', model1_full_sample.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade92',\n",
       " 'age',\n",
       " 'race_4',\n",
       " 'race_8',\n",
       " 'sex_2',\n",
       " 'prcitshp_Foreign Born, US Cit By Naturalization',\n",
       " 'prcitshp_Native, Born In US',\n",
       " 'chldpres',\n",
       " 'class_Government - State',\n",
       " 'marital_4',\n",
       " 'marital_5',\n",
       " 'marital_7',\n",
       " 'unionmme_Yes']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_features = ['ownchild', 'chldpres', 'class','marital','unionmme']\n",
    "model_2_features = model_1_features\n",
    "for feat in extra_features:\n",
    "    model_2_features += [i for i in selected_features if feat in i]\n",
    "model_2_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 13)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_model_2 = X_scaled[:, [i for i in range(len(X.columns)) if X.columns[i] in model_2_features]]\n",
    "X_scaled_model_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with cross validation is:  25.247284818410307\n"
     ]
    }
   ],
   "source": [
    "# Building the 2nd OLS model using cross validation\n",
    "model2 = LinearRegression()\n",
    "y_pred_cv = cross_val_predict(model2, X_scaled_model_2, y, cv=5)\n",
    "rmse_cv_value = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "RMSE_CV.append(rmse_cv_value)\n",
    "print('RMSE of OLS model with cross validation is: ', rmse_cv_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with full sample is:  25.11443298702469\n",
      "BIC of OLS model with full sample is:  21602.68542056904\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the OLS model using full sample and calculating the RMSE and BIC\n",
    "X_scaled_model_2 = sm.add_constant(X_scaled_model_2)\n",
    "model2_full_sample = sm.OLS(y, X_scaled_model_2).fit()\n",
    "y_pred_full_sample = model2_full_sample.predict(X_scaled_model_2)\n",
    "rmse_full_sample_value = np.sqrt(mean_squared_error(y, y_pred_full_sample))\n",
    "RMSE_full_sample.append(rmse_full_sample_value)\n",
    "BIC_full_sample.append(model2_full_sample.bic)\n",
    "print('RMSE of OLS model with full sample is: ', rmse_full_sample_value)\n",
    "print('BIC of OLS model with full sample is: ', model2_full_sample.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 57)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_features = selected_features\n",
    "X_scaled_model_3 = X_scaled[:, [i for i in range(len(X.columns)) if X.columns[i] in model_3_features]]\n",
    "X_scaled_model_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with cross validation is:  25.12315573289413\n"
     ]
    }
   ],
   "source": [
    "# Building the 3rd OLS model using cross validation\n",
    "model3 = LinearRegression()\n",
    "y_pred_cv = cross_val_predict(model3, X_scaled_model_3, y, cv=5)\n",
    "rmse_cv_value = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "RMSE_CV.append(rmse_cv_value)\n",
    "print('RMSE of OLS model with cross validation is: ', rmse_cv_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with full sample is:  24.658807728491034\n",
      "BIC of OLS model with full sample is:  21858.792082817345\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the 3rd OLS model using full sample and calculating the RMSE and BIC\n",
    "X_scaled_model_3 = sm.add_constant(X_scaled_model_3)\n",
    "model3_full_sample = sm.OLS(y, X_scaled_model_3).fit()\n",
    "y_pred_full_sample = model3_full_sample.predict(X_scaled_model_3)\n",
    "rmse_full_sample_value = np.sqrt(mean_squared_error(y, y_pred_full_sample))\n",
    "RMSE_full_sample.append(rmse_full_sample_value)\n",
    "BIC_full_sample.append(model3_full_sample.bic)\n",
    "print('RMSE of OLS model with full sample is: ', rmse_full_sample_value)\n",
    "print('BIC of OLS model with full sample is: ', model3_full_sample.bic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the 4th OLS model, by including some interaction terms and some polynomial terms\n",
    "A = X_scaled_model_3[:, 1:]\n",
    "X_cp = pd.DataFrame(A, columns =  model_3_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_square] = X_cp[feature] ** 2\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_square] = X_cp[feature] ** 2\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_square] = X_cp[feature] ** 2\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_square] = X_cp[feature] ** 2\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_square] = X_cp[feature] ** 2\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
      "C:\\Users\\PA\\AppData\\Local\\Temp\\ipykernel_12140\\3247356159.py:8: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n"
     ]
    }
   ],
   "source": [
    "for feature in model_1_features:\n",
    "    new_feature_square = f\"{feature}^2\"\n",
    "    X_cp[new_feature_square] = X_cp[feature] ** 2\n",
    "    \n",
    "    for other_feature in model_1_features:\n",
    "        if feature != other_feature:\n",
    "            new_feature_interaction = f\"{feature}*{other_feature}\"\n",
    "            X_cp[new_feature_interaction] = X_cp[feature] * X_cp[other_feature]\n",
    "\n",
    "model_4_features = X_cp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2315, 226)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cp_scaled = scaler.fit_transform(X_cp)\n",
    "X_scaled_model_4 = X_cp_scaled[:, [i for i in range(len(X_cp.columns)) if X_cp.columns[i] in model_4_features]]\n",
    "X_scaled_model_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['grade92',\n",
       " 'age',\n",
       " 'race_4',\n",
       " 'race_8',\n",
       " 'sex_2',\n",
       " 'prcitshp_Foreign Born, US Cit By Naturalization',\n",
       " 'prcitshp_Native, Born In US',\n",
       " 'chldpres',\n",
       " 'class_Government - State',\n",
       " 'marital_4',\n",
       " 'marital_5',\n",
       " 'marital_7',\n",
       " 'unionmme_Yes']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with cross validation is:  257866971042583.38\n"
     ]
    }
   ],
   "source": [
    "# Building the 4th OLS model using cross validation\n",
    "model4 = LinearRegression()\n",
    "y_pred_cv = cross_val_predict(model4, X_scaled_model_4, y, cv=5)\n",
    "rmse_cv_value = np.sqrt(mean_squared_error(y, y_pred_cv))\n",
    "RMSE_CV.append(rmse_cv_value)\n",
    "print('RMSE of OLS model with cross validation is: ', rmse_cv_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE of OLS model with full sample is:  24.144798047414778\n",
      "BIC of OLS model with full sample is:  22303.561786717688\n"
     ]
    }
   ],
   "source": [
    "# Building the 4th OLS model, by including some interaction terms and some polynomial terms\n",
    "X_scaled_model_4 = sm.add_constant(X_scaled_model_4)\n",
    "model4_full_sample = sm.OLS(y, X_scaled_model_4).fit()\n",
    "y_pred_full_sample = model4_full_sample.predict(X_scaled_model_4)\n",
    "rmse_full_sample_value = np.sqrt(mean_squared_error(y, y_pred_full_sample))\n",
    "RMSE_full_sample.append(rmse_full_sample_value)\n",
    "BIC_full_sample.append(model4_full_sample.bic)\n",
    "print('RMSE of OLS model with full sample is: ', rmse_full_sample_value)\n",
    "print('BIC of OLS model with full sample is: ', model4_full_sample.bic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Num- Vars</th>\n",
       "      <th>RMSE_CV</th>\n",
       "      <th>RMSE_full_sample</th>\n",
       "      <th>BIC_full_sample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model_0</th>\n",
       "      <td>5</td>\n",
       "      <td>2.530182e+01</td>\n",
       "      <td>25.271251</td>\n",
       "      <td>21569.528608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_1</th>\n",
       "      <td>13</td>\n",
       "      <td>2.530579e+01</td>\n",
       "      <td>25.268129</td>\n",
       "      <td>21584.450849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_2</th>\n",
       "      <td>13</td>\n",
       "      <td>2.524728e+01</td>\n",
       "      <td>25.114433</td>\n",
       "      <td>21602.685421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_3</th>\n",
       "      <td>57</td>\n",
       "      <td>2.512316e+01</td>\n",
       "      <td>24.658808</td>\n",
       "      <td>21858.792083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model_4</th>\n",
       "      <td>226</td>\n",
       "      <td>2.578670e+14</td>\n",
       "      <td>24.144798</td>\n",
       "      <td>22303.561787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Num- Vars       RMSE_CV  RMSE_full_sample  BIC_full_sample\n",
       "model_0          5  2.530182e+01         25.271251     21569.528608\n",
       "model_1         13  2.530579e+01         25.268129     21584.450849\n",
       "model_2         13  2.524728e+01         25.114433     21602.685421\n",
       "model_3         57  2.512316e+01         24.658808     21858.792083\n",
       "model_4        226  2.578670e+14         24.144798     22303.561787"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a dataframe to store the RMSE and BIC values\n",
    "results = pd.DataFrame()\n",
    "results['Num- Vars'] = [len(i) for i in [model_0_features, model_1_features, model_2_features, model_3_features, model_4_features]]\n",
    "results['RMSE_CV'] = RMSE_CV\n",
    "results['RMSE_full_sample'] = RMSE_full_sample\n",
    "results['BIC_full_sample'] = BIC_full_sample\n",
    "results.index = ['model_0', 'model_1', 'model_2', 'model_3', 'model_4']\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_complexity = range(0, 5)\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(model_complexity, RMSE_full_sample, marker='o')\n",
    "plt.title('RMSE (Full Sample)')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(model_complexity, RMSE_CV, marker='o')\n",
    "plt.title('RMSE (Cross-Validated)')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('RMSE')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(model_complexity, BIC_full_sample, marker='o')\n",
    "plt.title('BIC (Full Sample)')\n",
    "plt.xlabel('Model Complexity')\n",
    "plt.ylabel('BIC')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
